{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"E:\\data\\models\\gpt-2\\gpt-2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"E:\\data\\models\\gpt-2\\gpt-2-xl\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshengqiang/.cache\\torch\\transformers\\18d7ac53606f670f979f24836b00f5dfee1c58d79bdbcc58411265f194d88ac0.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text,):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    max_generated_len = 20\n",
    "    generated_ids = []\n",
    "\n",
    "    stop_id = [198]\n",
    "\n",
    "    for i in range(max_generated_len):\n",
    "        input_len = input_ids.size(1)\n",
    "        outputs = model.generate(input_ids=input_ids, max_length=input_len+1, do_sample=True, top_k=1, temperature=1, pad_token_id=50256)\n",
    "        output_id = outputs[0][-1]\n",
    "        generated_ids.append(output_id)\n",
    "        input_ids = input_ids.tolist()\n",
    "        input_ids[0].append(output_id)\n",
    "        input_ids = torch.LongTensor(input_ids).to(device)\n",
    "\n",
    "        if output_id.item() in stop_id:\n",
    "            break\n",
    "\n",
    "    result = tokenizer.decode(generated_ids)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: iptables -A INPUT -p tcp --dport 22 -j DROP\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: List files\n",
    "Output: ls -l\n",
    "Input: Count files in a directory\n",
    "Output: ls -l | wc -l\n",
    "Input: Disk space used by home directory\n",
    "Output: du ~\n",
    "Input: Replace foo with bar in all .py files\n",
    "Output: sed -i .bak -- 's/foo/bar/g' *.py\n",
    "Input: Delete the models subdirectory\n",
    "Output: rm -rf ./models\n",
    "Input: Firewall all incoming connections to port 22 on this machine.\n",
    "Output: iptables -A INPUT -p tcp --dport 22 -j ACCEP\n",
    "Input: I think ACCEPT should be replaced by DROP\n",
    "\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The first fax was sent in 1876.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: What is human life expectancy in the United States?\n",
    "A: Human life expectancy in the United States is 78 years.\n",
    "\n",
    "Q: Who was president of the United States in 1955?\n",
    "A: Dwight D. Eisenhower was president of the United States in 1955.\n",
    "\n",
    "Q: What party did he belong to?\n",
    "A: He belonged to the Republican Party.\n",
    "\n",
    "Q: Who was president of the United States before George W. Bush?\n",
    "A: Bill Clinton was president of the United States before George W. Bush.\n",
    "\n",
    "Q: Who won the World Series in 1995?\n",
    "A: The Atlanta Braves won the World Series in 1995.\n",
    "\n",
    "Q: What year was the first fax sent?\n",
    "A:\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thank you for picking me as your designer. I would appreciate it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Poor English: Please provide me with a short brief of the design you’re looking for and that’d be nice if you could share some examples or project you did before.\n",
    "Corrected English: Please provide me with a short brief of the design you’re looking for and some examples or previous projects you’ve done would be helpful.\n",
    "Poor English: If I’m stressed out about something, I tend to have problem to fall asleep.\n",
    "Corrected English: If I’m stressed out about something, I tend to have a problem falling asleep.\n",
    "Poor English: There is plenty of fun things to do in the summer when your able to go outside.\n",
    "Corrected English: There are plenty of fun things to do in the summer when you are able to go outside.\n",
    "Poor English: She no went to the market.\n",
    "Corrected English: She didn’t go to the market.\n",
    "Poor English: Thank you for picking me as your designer. I’d appreciate it.\n",
    "Corrected English:\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pounits | Neon pink | Sour |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\n",
    "\n",
    "Please make a table summarizing the fruits from Goocrux\n",
    "| Fruit | Color | Flavor |\n",
    "| Neoskizzles | Purple | Sweet |\n",
    "| Loheckles | Grayish blue | Tart |\n",
    "|\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"\"\"We’re releasing an API for accessing new AI models developed by OpenAI. Unlike most AI systems which are designed for one use-case, the API today provides a general-purpose “text in, text out” interface, allowing users to try it on virtually any English language task. You can now request access in order to integrate the API into your product, develop an entirely new application, or help us explore the strengths and limits of this technology. The\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "基于人工智能的城市建设方案设计=人工智能、城市建设\n",
    "基于SSM框架的图书管理系统的实现=SSM框架、图书管理系统\n",
    "基于SpringBoot的后台管理系统设计与实现=SpringBoot、后台管理系统\n",
    "基于生成式对抗网络的医疗文本生成方法=生成式对抗网络、医疗文本生成\n",
    "基于深度学习的图像识别鲁棒性研究=深度学习、图像识别鲁棒性\n",
    "永磁同步电机系统神经网络逆解耦控制=神经网络逆解偶控制、永磁同步电机系统\n",
    "基于Vue的外卖系统页面实现=Vue、外卖系统页面\n",
    "青年毛泽东思想转变的个性化因素探析=青年毛泽东思想转变、个性化因素\n",
    "基于深度学习的无人车避障策略研究=\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"\"\"中国的首都是北京\n",
    "日本的首都是东京\n",
    "韩国的首都是首尔\n",
    "俄罗斯的首都是莫斯科\n",
    "美国的首都是华盛顿\n",
    "澳大利亚的首都是\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"\"\"Are more and more young people starting to hate real estate, and why?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " API is available for free, and we welcome your feedback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Are more and more young people starting to hate real estate, and why?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深度学习、无人车避障\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "基于人工智能的城市建设方案设计=人工智能、城市建设\n",
    "基于SSM框架的图书管理系统的实现=SSM框架、图书管理系统\n",
    "基于SpringBoot的后台管理系统设计与实现=SpringBoot、后台管理系统\n",
    "基于生成式对抗网络的医疗文本生成方法=生成式对抗网络、医疗文本生成\n",
    "基于深度学习的图像识别鲁棒性研究=深度学习、图像识别鲁棒性\n",
    "永磁同步电机系统神经网络逆解耦控制=神经网络逆解偶控制、永磁同步电机系统\n",
    "基于Vue的外卖系统页面实现=Vue、外卖系统页面\n",
    "青年毛泽东思想转变的个性化因素探析=青年毛泽东思想转变、个性化因素\n",
    "基于深度学习的无人车避障策略研究=\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "澳大科\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"中国的首都是北京\n",
    "日本的首都是东京\n",
    "韩国的首都是首尔\n",
    "俄罗斯的首都是莫斯科\n",
    "美国的首都是华盛顿\n",
    "澳大利亚的首都是\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is simple: the housing market is a bubble.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Are more and more young people starting to hate real estate, and why?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = generate(prompt)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}